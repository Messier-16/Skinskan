{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skinskan_resnet50.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xhH6vXiYESvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model, optimizers\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class ImageProcessingModel:\n",
        "    VALIDATION_SPLIT = 0.1\n",
        "    RESNET_TRANSFERRED_LAYER_COUNT = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(image_path):\n",
        "        img = Image.open(image_path)\n",
        "        img.load()\n",
        "        data = np.asarray(img, dtype=\"int32\")\n",
        "        return data\n",
        "\n",
        "    def __init__(self, dataset_directory_name, metadata_file_name, x_col, y_col, target_size):\n",
        "        dataset = pd.read_csv(f\"{dataset_directory_name}/{metadata_file_name}\")\n",
        "\n",
        "        dataset[\"image_id\"] = dataset_directory_name + \"/\" + dataset[x_col] + \".jpg\"\n",
        "\n",
        "        total_image_count = len(dataset)\n",
        "        training_image_count = total_image_count * (1 - ImageProcessingModel.VALIDATION_SPLIT)\n",
        "        validation_image_count = total_image_count - training_image_count\n",
        "\n",
        "        image_data_generator = ImageDataGenerator(validation_split = ImageProcessingModel.VALIDATION_SPLIT)\n",
        "\n",
        "        batch_size = 1\n",
        "\n",
        "        self.train_image_data_yielder = image_data_generator.flow_from_dataframe(dataframe = dataset, batch_size = batch_size, x_col = x_col, y_col = y_col, target_size = target_size, subset = \"training\")\n",
        "        self.validate_image_data_yielder = image_data_generator.flow_from_dataframe(dataframe = dataset, batch_size = batch_size, x_col = x_col, y_col = y_col, target_size = target_size, subset = \"validation\")\n",
        "\n",
        "        transferred_model = ResNet50(include_top = False, weights = \"imagenet\", input_shape = (*target_size, 3))\n",
        "\n",
        "        transferred_model.load_weights(\"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
        "\n",
        "        for frozen_layer in transferred_model.layers[:ImageProcessingModel.RESNET_TRANSFERRED_LAYER_COUNT]:\n",
        "            frozen_layer.trainable = False\n",
        "\n",
        "        extra_layer = transferred_model.output\n",
        "        extra_layer = Flatten()(extra_layer)\n",
        "        extra_layer = Dropout(0.5)(extra_layer)\n",
        "\n",
        "        class_count = dataset[y_col].nunique()\n",
        "        predictions = Dense(class_count, activation = \"softmax\")(extra_layer)\n",
        "\n",
        "        self.final_model = Model(input = transferred_model.input, output = predictions)\n",
        "        final_model_optimizer = optimizers.SGD(lr = 10e-2)\n",
        "\n",
        "        self.final_model.compile(loss = \"categorical_crossentropy\", optimizer = final_model_optimizer, metrics = [\"accuracy\"])\n",
        "\n",
        "        self.training_steps_per_epoch = training_image_count // batch_size\n",
        "        self.validation_steps_per_epoch = validation_image_count // batch_size\n",
        "\n",
        "    def train(self, epochs):\n",
        "        self.final_model.fit_generator(self.train_image_data_yielder, steps_per_epoch = self.training_steps_per_epoch, epochs = epochs, validation_data = self.validate_image_data_yielder, validation_steps = self.validation_steps_per_epoch)\n",
        "\n",
        "class ISICModel(ImageProcessingModel):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"isic\", \"HAM10000_metadata.csv\", \"image_id\", \"dx\", (600, 450))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}